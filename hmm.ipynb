{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masa512/hidden_markov_model/blob/main/hmm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KcNehED7HcAq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Model\n",
        "\n",
        "This codebook intends to dig into implementation of single-observation Markov Model for a given time sequence data.\n",
        "\n",
        "We have the following quantities\n",
        "\n",
        "$A : \\{a_{ij}\\} = P\\{q_{t+1}=S_j | q_{t}=S_i\\}$ : (N,N)\n",
        "\n",
        "$B : \\{b_j(O_{t})\\} = P\\{O_{t} = v_k | q_{t} = S_j\\}$ : (M,N)\n",
        "\n",
        "$P_0 : \\{\\pi_i\\} = P(q_1 = S_i)$ \n",
        "\n",
        "We finally refer to $\\lambda$ as the model parameter set $\\{A,B,P_0\\}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6gMDogKNHm5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# The Forward Algorithm\n",
        "\n",
        "The forward algorithm uses dynamic programming to evaluate the following quantity\n",
        "\n",
        "$$\\alpha_t(i) = P\\{\\{ O_n\\}_0^t,q_t=S_i | \\lambda\\}$$\n",
        "\n",
        "We will process the update using the following steps : \n",
        "\n",
        "\n",
        "\n",
        "1. Initial :\n",
        "> $\\alpha_1(i) = \\pi_i b_i(O_1)$\n",
        "\n",
        "2. Updating :\n",
        "> $\\alpha_{t+1}(j) = [\\sum_{i=1}^N \\alpha_t(i)a_{ij}]b_j(O_{t+1})$\n",
        "\n",
        "3. Terminal :\n",
        "> $P\\{O|\\lambda\\} = \\sum_{i=1}^{N} \\alpha_{T}(i)$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xZPjjbOrLLNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets implement the initialization process of a HMM model\n",
        "\n",
        "def init_hmm(N,M):\n",
        "  \"\"\"\n",
        "  Input\n",
        "  N (Scalar): Number of states\n",
        "  M (Scalar): Number of possible emissions\n",
        "\n",
        "  Output\n",
        "  A (N,N): Transition matrix from state i to state j\n",
        "  B (M,N): Emission at state i\n",
        "  P (N,) : Priori probability for each state\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize P\n",
        "  P = np.random.rand(N,)\n",
        "  P = P/np.sum(P)\n",
        "\n",
        "  # Initialize A\n",
        "  A = np.random.rand(N,N)\n",
        "  A = A/np.sum(A,axis=0,keepdims=True)\n",
        "  # Initialize B\n",
        "  B = np.random.rand(M,N)\n",
        "  B = B/np.sum(B,axis=0,keepdims= True)\n",
        "\n",
        "  return (A,B,P)\n",
        "\n",
        "\n",
        "# Lets implement the forward algorithm of HMM model\n"
      ],
      "metadata": {
        "id": "W4qFyeljHlle"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_alg(V,A,B,P):\n",
        "  \"\"\"\n",
        "  Forward probability evaluation using Observations V\n",
        "\n",
        "  Input\n",
        "  V (T,) : Observation sequence of length T (V[t] is t-th observation value given)\n",
        "  A (N,N): Transition matrix\n",
        "  B (M,N): Emission matrix at given state\n",
        "  P (N,) : Priori state probability\n",
        "\n",
        "  Output\n",
        "  Alpha (T,N): Forward probability\n",
        "  out_prob (Scalar): The terminal probability of output sequence for model\n",
        "  \"\"\"\n",
        "\n",
        "  Alpha = np.zeros((V.shape[0],P.shape[0]))\n",
        "\n",
        "  # initial condition\n",
        "  Alpha[0,:] = (B[V[0]] * P).reshape(-1,)\n",
        "  \n",
        "  # Loop the rest\n",
        "  for t in range(1,V.shape[0]):\n",
        "    prev_alp = Alpha[t-1,:] # Length N\n",
        "    Alpha[t,:] = (B[V[t]] * (A @ prev_alp)).reshape(-1,)\n",
        "  \n",
        "  # Terminal Condition\n",
        "  out_prob = np.sum(Alpha[-1,:],keepdims=False)\n",
        "\n",
        "  return out_prob, Alpha\n",
        "  "
      ],
      "metadata": {
        "id": "F-q-MRi8Vse3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the forward operation\n",
        "\n",
        "(N,M) = (3,4)\n",
        "A,B,P = init_hmm(N,M)\n",
        "\n",
        "V = np.array([3,1,1,0]) # My observation\n",
        "\n",
        "out_prob, Alpha = forward_alg(V,A,B,P)\n"
      ],
      "metadata": {
        "id": "tguEhIfcuHaG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backward Probability\n",
        "\n",
        "The Backward probability evaluates the following: \n",
        "\n",
        "$$\\beta_{t}(j) = P\\{ \\{O_n\\}_{n=t+1}^T | q_{t} = S_j\\}$$\n",
        "\n",
        "In the implementation, we use the following methods to calculate $\\beta$\n",
        "\n",
        "\n",
        "\n",
        "1.   Initial:\n",
        "> $\\beta_T(j) = 1$\n",
        "2.   Inductive:\n",
        "> $\\beta_t(j) = \\sum_{i = 1}^{N} a_{ij}b_j(O_{t+1})\\beta_{t+1}(i)$\n",
        "\n"
      ],
      "metadata": {
        "id": "io8Wvg831VQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will furthermore define the backward operation as well\n",
        "def Backward_alg(V,A,B,P):\n",
        "  \"\"\"\n",
        "  Forward probability evaluation using Observations V\n",
        "\n",
        "  Input\n",
        "  V (T,) : Observation sequence of length T (V[t] is t-th observation value given)\n",
        "  A (N,N): Transition matrix\n",
        "  B (M,N): Emission matrix at given state\n",
        "  P (N,) : Priori state probability\n",
        "\n",
        "  Output\n",
        "  Beta (T,N): Backward probability\n",
        "  \"\"\"\n",
        "\n",
        "  Beta = np.zeros((V.shape[0],A.shape[0]))\n",
        "\n",
        "  # Initial condition\n",
        "  Beta[-1,:] = np.ones((A.shape[0],))\n",
        "\n",
        "  # Iteration\n",
        "  for t in range(V.shape[0]-2,-1,-1):\n",
        "    prev_beta = Beta[t+1,:]\n",
        "    Beta[t,:] = B[V[t+1],:]*(A @ prev_beta)\n",
        "  \n",
        "  return Beta"
      ],
      "metadata": {
        "id": "CAcw8H38uO9z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the backward operation\n",
        "\n",
        "(N,M) = (3,4)\n",
        "A,B,P = init_hmm(N,M)\n",
        "\n",
        "V = np.array([3,1,1,0]) # My observations\n",
        "\n",
        "Beta = Backward_alg(V,A,B,P)"
      ],
      "metadata": {
        "id": "An9-UOhC0Psr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward-Backward Variable and Adjacence probability\n",
        "\n",
        "First, we define $\\gamma_t(i)$ as the following:\n",
        "$$\\gamma_t(i) = P\\{q_t=S_i | \\{O_i\\}, \\lambda\\}$$\n",
        "\n",
        "which can be evaluated using the forward and backward parameters:\n",
        "\n",
        "$$=\\frac{\\alpha_t(i)\\beta_{t}(i)}{P\\{\\{O\\}|\\lambda\\}} = \\frac{\\alpha_t(i)\\beta_{t}(i)}{\\sum_{i=1}^N \\alpha_t(i)\\beta_{t}(i)} $$\n",
        "\n",
        "Lastly, we define the adjacence probability $\\zeta_t(i,j)$ with the following:\n",
        "$$\\zeta_t(i,j) = P\\{q_t = S_i, q_{t+1} = S_j | \\{O\\},\\lambda\\}$$\n",
        "\n",
        "Which can be explicitly evaluated by:\n",
        "\n",
        "$$ = \\frac{\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j)}{\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j)} $$\n",
        "\n",
        "**NOTE:** $$\\gamma_t(i) = \\sum_{i=1}^{N} \\zeta_t(i,j)$$"
      ],
      "metadata": {
        "id": "dfh8YWabSHtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_zeta(V,A,B,alpha,beta):\n",
        "\n",
        "  \"\"\"\n",
        "  The expectation step for HMM prediction\n",
        "\n",
        "  Input:\n",
        "  V (T,) : Vector of inputs\n",
        "  A (N,N) : Transition matrix\n",
        "  B (M,N): Emission matrixx\n",
        "  P (N,) : Priori state\n",
        "\n",
        "  Alpha (T,N): Forward probability\n",
        "  Beta (T,N): Backward probability\n",
        "  \"\"\"\n",
        "\n",
        "  T = alpha.shape[0]\n",
        "  N = A.shape[0]\n",
        "  M = B.shape[0]\n",
        "\n",
        "  zeta = (T-1)*[0]\n",
        "  den = (T-1)*[0]\n",
        "  for t in range(T-1):\n",
        "    for i in range(N):\n",
        "      for j in range(N):\n",
        "        num = alpha[t,i]*A[i,j]*B[V[t+1],j]*beta[t+1,j]\n",
        "        zeta[t] = num\n",
        "        den[t] = den[t]+num\n",
        "    zeta[t] = zeta[t]/den[t]\n",
        "  return zeta\n",
        "\n",
        "\n",
        "def eval_gamma(V,A,B,alpha,beta):\n",
        "\n",
        "  \"\"\"\n",
        "  The expectation step for HMM prediction\n",
        "\n",
        "  Input:\n",
        "  V (T,) : Vector of inputs\n",
        "  A (N,N) : Transition matrix\n",
        "  B (M,N): Emission matrixx\n",
        "  P (N,) : Priori state\n",
        "\n",
        "  Alpha (T,N): Forward probability\n",
        "  Beta (T,N): Backward probability\n",
        "  \"\"\"\n",
        "\n",
        "  T = alpha.shape[0]\n",
        "  N = A.shape[0]\n",
        "  M = B.shape[0]\n",
        "  print(alpha.shape)\n",
        "  print(beta.shape)\n",
        "  gamma = (T)*[0]\n",
        "  den = (T)*[0]\n",
        "\n",
        "  for t in range(T):\n",
        "    gamma_t = np.zeros((N,))\n",
        "    for i in range(N):\n",
        "      print(t)\n",
        "      gamma_t[i] = alpha[t,i]*beta[t,i]\n",
        "      den[t] = alpha[t,i]*beta[t,i]\n",
        "    gamma[t] = gamma_t/den[t]\n",
        "\n",
        "  return gamma\n",
        "\n",
        "def E_step(V,A,B,P,alpha,beta):\n",
        "  \"\"\"\n",
        "  The expectation step for HMM prediction\n",
        "\n",
        "  Input:\n",
        "  V (T,) : Vector of inputs\n",
        "  A (N,N) : Transition matrix\n",
        "  B (M,N): Emission matrixx\n",
        "  P (N,) : Priori state\n",
        "  \"\"\"\n",
        "  zeta = eval_zeta(V,A,B,alpha,beta)\n",
        "  gamma = eval_gamma(V,A,B,alpha,beta)\n",
        "  return adj, gamma\n"
      ],
      "metadata": {
        "id": "l-A_MU4i4sOd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maximization step\n",
        "\n",
        "We will now update the model paramters using Baum-Welch with following formula\n",
        "\n",
        "$$a_{ij} = \\frac{\\sum_{t=1}^{T-1} \\zeta_{ij}(t)}{\\sum_{i=1}^{T-1}\\sum_{j=1}^{N} \\zeta_{ij}(t)}$$\n",
        "\n",
        "$$b_j(V(k)) = \\frac{\\sum_{t=1}^{T}\\gamma_t(i)1(v(t)=k)}{\\sum_{t=1}^{T}\\gamma_t(i)}$$\n",
        "\n",
        "$$\\pi_i = \\gamma_i(0)$$"
      ],
      "metadata": {
        "id": "0ODHkai635cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def M_step(adj,gamma,V,M):\n",
        "  \"\"\"\n",
        "  The maximization step\n",
        "  \"\"\"\n",
        "  A = sum(adj)/(sum([np.sum(a,axis=0).reshape(1,-1) for a in adj]))\n",
        "  print(gamma)\n",
        "  N = gamma[0].shape[0]\n",
        "  # Updating b a bit complicated\n",
        "  B = np.zeros((M,N))\n",
        "  T = V.shape[0]\n",
        "  for k in range(M):\n",
        "    mask = 1*(V == k)\n",
        "    S = 0\n",
        "    for t in range(T):\n",
        "      S += mask[t]*gamma[t]\n",
        "    B[k,:] = S/sum(gamma)\n",
        "  \n",
        "  # Updating pi\n",
        "  P = gamma[0]\n",
        "  return A,B,P"
      ],
      "metadata": {
        "id": "AtJI8dbp2fg1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "GA2lHVMnybUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "\n",
        "(N,M) = (3,4)\n",
        "A,B,P = init_hmm(N,M)\n",
        "n_epochs = 2\n",
        "\n",
        "T = 10\n",
        "V = np.random.randint(0,M,size=(T,))\n",
        "\n",
        "for n in range(n_epochs):\n",
        "  print(f'Epoch: {n+1}\\n')\n",
        "  print(f'Ashape = {A.shape}')\n",
        "  print(f'Bshape = {B.shape}')\n",
        "  print(f'Pshape = {P.shape}')\n",
        "  \n",
        "  # Forward step & Backward Step\n",
        "  _, alpha = forward_alg(V,A,B,P)\n",
        "  beta = Backward_alg(V,A,B,P)\n",
        "\n",
        "\n",
        "  # Expectation Step\n",
        "  adj, gamma = E_step(V,A,B,P,alpha,beta)\n",
        "  \n",
        "  # Maximization\n",
        "  A,B,P = M_step(adj,gamma,V,M)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "HV3CIWh2ycsI",
        "outputId": "87acb55a-172e-44e4-ecf5-6830afc3fcd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "\n",
            "Ashape = (3, 3)\n",
            "Bshape = (4, 3)\n",
            "Pshape = (3,)\n",
            "(10, 3)\n",
            "(10, 3)\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "4\n",
            "4\n",
            "5\n",
            "5\n",
            "5\n",
            "6\n",
            "6\n",
            "6\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "8\n",
            "8\n",
            "9\n",
            "9\n",
            "9\n",
            "[array([0.19982146, 2.48412761, 1.        ]), array([0.75008704, 1.89840304, 1.        ]), array([0.41571744, 1.47380234, 1.        ]), array([0.77970047, 1.11980968, 1.        ]), array([0.84710936, 2.72845308, 1.        ]), array([0.66747067, 4.03867055, 1.        ]), array([0.53200064, 1.54896558, 1.        ]), array([1.28389804, 0.99797166, 1.        ]), array([0.77328807, 0.84657273, 1.        ]), array([0.4951953 , 0.57951168, 1.        ])]\n",
            "Epoch: 2\n",
            "\n",
            "Ashape = (1, 3)\n",
            "Bshape = (4, 3)\n",
            "Pshape = (3,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b51d4a8118f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Forward step & Backward Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackward_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d17ac7db3828>\u001b[0m in \u001b[0;36mBackward_alg\u001b[0;34m(V, A, B, P)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprev_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mBeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mprev_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mBeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3MjiXCq1NMl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}