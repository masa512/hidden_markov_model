{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masa512/hidden_markov_model/blob/main/hmm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KcNehED7HcAq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Model\n",
        "\n",
        "This codebook intends to dig into implementation of single-observation Markov Model for a given time sequence data.\n",
        "\n",
        "We have the following quantities\n",
        "\n",
        "$A : \\{a_{ij}\\} = P\\{q_{t+1}=S_j | q_{t}=S_i\\}$ : (N,N)\n",
        "\n",
        "$B : \\{b_j(O_{t})\\} = P\\{O_{t} = v_k | q_{t} = S_j\\}$ : (M,N)\n",
        "\n",
        "$P_0 : \\{\\pi_i\\} = P(q_1 = S_i)$ \n",
        "\n",
        "We finally refer to $\\lambda$ as the model parameter set $\\{A,B,P_0\\}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6gMDogKNHm5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# The Forward Algorithm\n",
        "\n",
        "The forward algorithm uses dynamic programming to evaluate the following quantity\n",
        "\n",
        "$$\\alpha_t(i) = P\\{\\{ O_n\\}_0^t,q_t=S_i | \\lambda\\}$$\n",
        "\n",
        "We will process the update using the following steps : \n",
        "\n",
        "\n",
        "\n",
        "1. Initial :\n",
        "> $\\alpha_1(i) = \\pi_i b_i(O_1)$\n",
        "\n",
        "2. Updating :\n",
        "> $\\alpha_{t+1}(j) = [\\sum_{i=1}^N \\alpha_t(i)a_{ij}]b_j(O_{t+1})$\n",
        "\n",
        "3. Terminal :\n",
        "> $P\\{O|\\lambda\\} = \\sum_{i=1}^{N} \\alpha_{T}(i)$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xZPjjbOrLLNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets implement the initialization process of a HMM model\n",
        "\n",
        "def init_hmm(N,M):\n",
        "  \"\"\"\n",
        "  Input\n",
        "  N (Scalar): Number of states\n",
        "  M (Scalar): Number of possible emissions\n",
        "\n",
        "  Output\n",
        "  A (N,N): Transition matrix from state i to state j\n",
        "  B (M,N): Emission at state i\n",
        "  P (N,) : Priori probability for each state\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize P\n",
        "  P = np.random.rand(N,)\n",
        "  P = P/np.sum(P)\n",
        "\n",
        "  # Initialize A\n",
        "  A = np.random.rand(N,N)\n",
        "  A = A/np.sum(A,axis=0,keepdims=True)\n",
        "  # Initialize B\n",
        "  B = np.random.rand(M,N)\n",
        "  B = B/np.sum(B,axis=0,keepdims= True)\n",
        "\n",
        "  return (A,B,P)\n",
        "\n",
        "\n",
        "# Lets implement the forward algorithm of HMM model\n"
      ],
      "metadata": {
        "id": "W4qFyeljHlle"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_alg(V,A,B,P):\n",
        "  \"\"\"\n",
        "  Forward probability evaluation using Observations V\n",
        "\n",
        "  Input\n",
        "  V (T,) : Observation sequence of length T (V[t] is t-th observation value given)\n",
        "  A (N,N): Transition matrix\n",
        "  B (M,N): Emission matrix at given state\n",
        "  P (N,) : Priori state probability\n",
        "\n",
        "  Output\n",
        "  Alpha (T,N): Forward probability\n",
        "  out_prob (Scalar): The terminal probability of output sequence for model\n",
        "  \"\"\"\n",
        "\n",
        "  Alpha = np.zeros((V.shape[0],P.shape[0]))\n",
        "\n",
        "  # initial condition\n",
        "  Alpha[0,:] = (B[V[0]] * P).reshape(-1,)\n",
        "  \n",
        "  # Loop the rest\n",
        "  for t in range(1,V.shape[0]):\n",
        "    prev_alp = Alpha[t-1,:] # Length N\n",
        "    Alpha[t,:] = (B[V[t]] * (A @ prev_alp)).reshape(-1,)\n",
        "  \n",
        "  # Terminal Condition\n",
        "  out_prob = np.sum(Alpha[-1,:],keepdims=False)\n",
        "\n",
        "  return out_prob, Alpha\n",
        "  "
      ],
      "metadata": {
        "id": "F-q-MRi8Vse3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the forward operation\n",
        "\n",
        "(N,M) = (3,4)\n",
        "A,B,P = init_hmm(N,M)\n",
        "\n",
        "V = np.array([3,1,1,0]) # My observation\n",
        "\n",
        "out_prob, Alpha = forward_alg(V,A,B,P)\n"
      ],
      "metadata": {
        "id": "tguEhIfcuHaG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backward Probability\n",
        "\n",
        "The Backward probability evaluates the following: \n",
        "\n",
        "$$\\beta_{t}(j) = P\\{ \\{O_n\\}_{n=t+1}^T | q_{t} = S_j\\}$$\n",
        "\n",
        "In the implementation, we use the following methods to calculate $\\beta$\n",
        "\n",
        "\n",
        "\n",
        "1.   Initial:\n",
        "> $\\beta_T(j) = 1$\n",
        "2.   Inductive:\n",
        "> $\\beta_t(j) = \\sum_{i = 1}^{N} a_{ij}b_j(O_{t+1})\\beta_{t+1}(i)$\n",
        "\n"
      ],
      "metadata": {
        "id": "io8Wvg831VQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will furthermore define the backward operation as well\n",
        "def Backward_alg(V,A,B,P):\n",
        "  \"\"\"\n",
        "  Forward probability evaluation using Observations V\n",
        "\n",
        "  Input\n",
        "  V (T,) : Observation sequence of length T (V[t] is t-th observation value given)\n",
        "  A (N,N): Transition matrix\n",
        "  B (M,N): Emission matrix at given state\n",
        "  P (N,) : Priori state probability\n",
        "\n",
        "  Output\n",
        "  Beta (T,N): Backward probability\n",
        "  \"\"\"\n",
        "\n",
        "  Beta = np.zeros((V.shape[0],A.shape[0]))\n",
        "\n",
        "  # Initial condition\n",
        "  Beta[-1,:] = np.ones((A.shape[0],))\n",
        "\n",
        "  # Iteration\n",
        "  for t in range(V.shape[0]-2,-1,-1):\n",
        "    prev_beta = Beta[t+1,:]\n",
        "    Beta[t,:] = B[V[t+1],:]*(A @ prev_beta)\n",
        "  \n",
        "  return Beta"
      ],
      "metadata": {
        "id": "CAcw8H38uO9z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the backward operation\n",
        "\n",
        "(N,M) = (3,4)\n",
        "A,B,P = init_hmm(N,M)\n",
        "\n",
        "V = np.array([3,1,1,0]) # My observations\n",
        "\n",
        "Beta = Backward_alg(V,A,B,P)"
      ],
      "metadata": {
        "id": "An9-UOhC0Psr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward-Backward Variable and Adjacence probability\n",
        "\n",
        "First, we define $\\gamma_t(i)$ as the following:\n",
        "$$\\gamma_t(i) = P\\{q_t=S_i | \\{O_i\\}, \\lambda\\}$$\n",
        "\n",
        "which can be evaluated using the forward and backward parameters:\n",
        "\n",
        "$$=\\frac{\\alpha_t(i)\\beta_{t}(i)}{P\\{\\{O\\}|\\lambda\\}} = \\frac{\\alpha_t(i)\\beta_{t}(i)}{\\sum_{i=1}^N \\alpha_t(i)\\beta_{t}(i)} $$\n",
        "\n",
        "Lastly, we define the adjacence probability $\\zeta_t(i,j)$ with the following:\n",
        "$$\\zeta_t(i,j) = P\\{q_t = S_i, q_{t+1} = S_j | \\{O\\},\\lambda\\}$$\n",
        "\n",
        "Which can be explicitly evaluated by:\n",
        "\n",
        "$$ = \\frac{\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j)}{\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j)} $$\n",
        "\n",
        "**NOTE:** $$\\gamma_t(i) = \\sum_{i=1}^{N} \\zeta_t(i,j)$$"
      ],
      "metadata": {
        "id": "dfh8YWabSHtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def E_step(V,A,B,P,alpha,beta):\n",
        "  \"\"\"\n",
        "  The expectation step for HMM prediction\n",
        "\n",
        "  Input:\n",
        "  V (T,) : Vector of inputs\n",
        "  A (N,N) : Transition matrix\n",
        "  B (M,N): Emission matrixx\n",
        "  P (N,) : Priori state\n",
        "  \"\"\"\n",
        "\n",
        "  T = alpha.shape[0]\n",
        "  adj = T*[0]\n",
        "  gamma = T*[0]\n",
        "  \n",
        "  for t in range(T-1):\n",
        "    # we first evaluate the adj as vector of length T\n",
        "    adj[t] = (alpha[t:t+1,:]@beta[t+1:t+2,:].T) * (A@B[V[t+1],:]).reshape(1,-1)\n",
        "    adj[t] = adj[t]/np.sum(adj[t])\n",
        "\n",
        "    # We can use adj[t] to evaluate the gamma\n",
        "    gamma[t] = (alpha[t]*beta[t])/np.sum((alpha[t]*beta[t]))\n",
        "  \n",
        "  return adj, gamma\n"
      ],
      "metadata": {
        "id": "l-A_MU4i4sOd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maximization step\n",
        "\n",
        "We will now update the model paramters using Baum-Welch with following formula\n",
        "\n",
        "$$a_{ij} = \\frac{\\sum_{t=1}^{T-1} \\zeta_{ij}(t)}{\\sum_{i=1}^{T-1}\\sum_{j=1}^{N} \\zeta_{ij}(t)}$$\n",
        "\n",
        "$$b_j(V(k)) = \\frac{\\sum_{t=1}^{T-1}\\gamma_t(i)1(v(t)=k)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}$$\n"
      ],
      "metadata": {
        "id": "0ODHkai635cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def M_step(adj,gamma):\n",
        "  \"\"\"\n",
        "  The maximization step\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "AtJI8dbp2fg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}